1.What are microservices?
- Microservices are a software architecture style where an application is structured as a collection of small,
loosely coupled, independently deployable services.Each service is focused on doing one specific business
function well.

2. Advantages of Microservices ?
- Independent Deployability:
- Single Responsibility: Each service is responsible for a specific feature or functionality
- Technology Agnostic: Services can be built using different programming languages or technologies
- Lightweight Communication: Typically, services communicate with each other using HTTP/REST, gRPC, or messaging systems like Kafka or RabbitMQ.
- Fault Isolation: A failure in one service doesn't necessarily bring down the entire system.
- Decentralized Data Management: Each service may manage its own database, reducing data coupling

3. Disadvantages/ Challenges of microservice ?
- Complexity in communication and data consistency
- Requires robust monitoring, logging, and security
- Higher initial setup and operational overhead

-Inter-Service Communication : Services must communicate over the network, Network latency, failures, or message serialization/deserialization can cause issues.
Needs robust retry logic, timeouts, and circuit breakers.
-Data Consistency : Each microservice typically owns its own database.You can't rely on traditional ACID transactions; need eventual consistency or patterns like sagas.
- Security : More services = more attack surfaces. Managing secrets and access control becomes more difficult.
- Monitoring & Debugging : Logs and errors are spread across many services.Requires centralized logging, tracing (e.g. OpenTelemetry, Jaeger), and metrics (e.g. Prometheus, Grafana).
- Deployment & DevOps Overhead : More services mean more pipelines, containers, and environments to manage.Requires CI/CD, container orchestration (e.g., Kubernetes), and infrastructure as code., Testing and deploying changes is more complex.
- Service Dependency Management : Changes in one service may require coordination with others.Versioning APIs and ensuring backward compatibility is critical.
- More demanding in terms of architecture and tooling expertise.

3. How do microservices differ from monolithic architecture?
Aspect	            Monolithic Architecture	                        Microservices Architecture
Structure	        Single, unified codebase	                    Collection of small, independent services
Development	        Simpler to develop initially	                Complex, requires managing multiple services
Deployment	        Deployed as a single unit	                    Services can be deployed independently
Scalability	        Scale the whole application                     Scale individual services
Fault Isolation	    One failure can affect the entire application	Failure isolated to specific services
Technology Stack	Typically uses one stack throughout	            Each service can use a different stack
Data Management	    Single database	                                Each service may have its own database
Communication	    Internal function/method calls	                Inter-service communication via APIs or messaging
Team Organization	Often requires tight coordination between teams	Teams can own and manage individual services
Codebase            Complexity	Becomes harder to manage            Easier to manage per service, but overall complexity rises
                       as the app grows
Testing         	Easier to test as one unit	                    More complex due to multiple services
Initial Setup	    Faster setup and development	                Requires robust infrastructure and DevOps
Best For	        Small to medium-sized applications	            Large, complex, or rapidly scaling applications

--------------------------------------------------------------------------------------
4. What are the key components of a microservices architecture?
Key components of microservices architecture are designed to enable modular, scalable, and independently deployable services
- Services (Microservices)
Definition: Small, independently deployable units focused on a specific business function.
Key Traits: Loosely coupled, Highly cohesive, Independently deployable.

- API Gateway: Entry point for clients; routes requests to appropriate microservices.
Responsibilities: Request routing, Authentication/authorization, Rate limiting, Aggregating responses

- Service Discovery:  Allows services to find and communicate with each other without hardcoded locations.
 Types :
  Client-side discovery (e.g., Netflix Eureka)
  Server-side discovery (e.g., with a load balancer)

- Authentication and Authorization:
- Centralized security management.Often implemented with: (OAuth2, JWT ) / Identity providers (e.g., Keycloak, Auth0)

- Monitoring and Logging:
Track health and performance of services.
Logging: ELK Stack (Elasticsearch, Logstash, Kibana), Fluentd

- Inter-Service Communication
Methods:
   Synchronous: REST/HTTP, gRPC
   Asynchronous: Messaging queues (Kafka, RabbitMQ, NATS)

- Configuration Management
 Centralized configuration service to manage environment-specific configs.
 Tools: Spring Cloud Config, Consul, etcd

- Data Management
Each service typically manages its own database (Database per service pattern).
Promotes isolation and avoids tight coupling.

- CI/CD Pipelines
 Automates testing, building, and deployment of services.
 Tools: Jenkins, GitLab CI/CD, GitHub Actions, Argo CD

- Testing Infrastructure : Unit tests, Integration tests, Contract tests (e.g., Pact) , End-to-end tests

----------------------------------------------------------------------------------------------------------

5. What is a service registry and why is it used?
A service registry is a centralized database or directory used in microservices architectures to keep track of all the
services available in a system, including their locations (network addresses), metadata, and status.

-Register themselves when they start up
-Deregister when they shut down
-Discover other services dynamically when needed

| Purpose               | Explanation                                                                  |
| --------------------- | ---------------------------------------------------------------------------- |
| **Service Discovery** | Allows services to find and communicate with each other dynamically.         |
| **Load Balancing**    | Supports client-side or server-side load balancing using multiple instances. |
| **Fault Tolerance**   | Helps reroute traffic away from failed service instances.                    |
| **Decoupling**        | Services don’t need hardcoded endpoints or configuration files.              |
| **Scaling**           | Makes it easy to add/remove instances as services scale up/down.             |

Common Service Registries:
Eureka (from Netflix)
Consul (by HashiCorp)
Zookeeper (by Apache)
Etcd (used in Kubernetes)

----------------------------------------------
6. How do microservices communicate with each other?

----------------------------------------------

7. What is REST and how is it used in microservices?
- REST (Representational State Transfer) is an architectural style for designing networked applications, especially web
services. It uses standard HTTP methods (like GET, POST, PUT, DELETE) to enable communication between clients and servers.
REST is stateless and resource-based and HTTP methods define what action is performed on that resource.
REST is a common way for services to communicate with each other over HTTP
-Each microservice typically exposes a RESTful API so that other services (or external clients) can interact with it
using HTTP requests.

Limitations :
| Limitation               | When it matters                                                     |
| ------------------------ | ------------------------------------------------------------------- |
| ❌ **Chattiness**         | Lots of small REST calls can slow down performance                  |
| ❌ **Tight Coupling**     | Services may need to know too much about each other’s API contracts |
| ❌ **Error Propagation**  | One failure (e.g. a service is down) can ripple through the system  |
| ⚠️ **No Built-in Async** | REST is mostly synchronous — harder to build reactive systems       |

Alternatives to REST in Microservices
gRPC (binary, fast, contract-based)
GraphQL (flexible queries)
Event-driven communication (via Kafka, RabbitMQ, etc.)

----------------------------------------------------------------------------------------

8. What is the role of an API Gateway in microservices?
- An API Gateway is a central entry point for all client requests in a microservices architecture. It acts as a reverse
proxy, routing requests to the appropriate microservice and handling cross-cutting concerns like authentication, rate
 limiting, and logging.


9. How do you handle service discovery in microservices?

10. What is meant by "bounded context"?

11. Kubernetes service registry and load balancing ?

----------------------------------------------------------------------------------------------
13. Java records ? Java 17
- We can read this class object but can't modify (Oly getter and no setter methods)
- You can initialize data only once and whatever we will have given while object creation that will be final.

----------------------------------------------------------------------------------------------
API Gateway / Edge server

14. Default service name, Servicename with lower case

Custom routing

-----------------------------------------------------------------------------------------------
15. Service discovery and load balancing in K8's
- Inside k8's envt connsider MS-A is calling MS-B (2 instances), If one instance of B is down k8's is down
Note :
- Instance is considered to be down when liveness and readliness of it is false.
-

internal Kubernetes DNS

-------------------------------------------------------------------------------------------------

16. Circuit breaker ? Resiliance4J / Hystrix
 OR How to make your system fault tolerant
 Explain ratelimitter , Timelimitter, Retry in Microservices.

 What is circuit breaker ?
 A Circuit Breaker is a design pattern that prevents an application from repeatedly trying to
perform an operation that's likely to fail. In microservices, it's typically implemented using tools
like Netflix Hystrix or Resilience4j. It helps to improve fault tolerance by providing fallback mechanisms
when a service is unavailable.

- Also refer circuit breaker notes
Order :
1. 🔁 Retry
2. 📉 RateLimiter
3. 🚦 CircuitBreaker
4. ⏱️ TimeLimiter
5. ⚙️ Your actual business logic (e.g., WebClient)

Ratelimitter and retry logic :
application.yml -

resilience4j:
  ratelimiter:
    instances:
      ms2Service:
        limitForPeriod: 5 # Guard allows 5 members every second - this time is configured below
        limitRefreshPeriod: 1s #
        timeoutDuration: 0   # If 6th member comes then don't allow him / fail immediately .. also it is not mandatory that 6th call should go for retry

# Then when does retry happens ? If RateLimiter permits the call, but the call fails with a retryable exception (like IOException or TimeoutException):Retry retries the call, again subject to RateLimiter checks for each retry
  retry:
    instances:
      ms2Service:
        maxAttempts: 3
        waitDuration: 500ms
        retryExceptions:
          - java.io.IOException                     // Decides in which situation retry should happen on req
          - java.util.concurrent.TimeoutException   // Decides in which situation retry should happen on req

# Time limitter :
resilience4j:
  timelimiter:
    instances:
      ms2Service:
        timeoutDuration: 2s   # Max allowed duration for a call
        cancelRunningFuture: true

resilience4j:
  circuitbreaker:
    instances:
      ms2Service:
        slidingWindowSize: 10                 # How many calls to evaluate
        minimumNumberOfCalls: 5              # Minimum calls to start evaluating
        failureRateThreshold: 50             # % failure rate to trip breaker
        slowCallDurationThreshold: 2s        # If a call takes longer, it’s "slow"
        slowCallRateThreshold: 50            # % slow calls to also trip breaker
        waitDurationInOpenState: 10s         # Stay OPEN this long before trying again


Below method in service class and called in controller :

@CircuitBreaker(name = "ms2Service", fallbackMethod = "circuitFallback")
@RateLimiter(name = "ms2Service", fallbackMethod = "rateLimitFallback")
@Retry(name = "ms2Service", fallbackMethod = "retryFallback")
@TimeLimiter(name = "ms2Service", fallbackMethod = "fallback")
public Mono<String> callMS2() {
    return webClient.get()
            .uri("/api/data")
            .retrieve()
            .bodyToMono(String.class)
            .timeout(Duration.ofSeconds(2)); // simulate possible timeout
}

public Mono<String> rateLimitFallback(RequestNotPermitted ex) {
    return Mono.just("❌ Rate limit exceeded! Guard says: Wait your turn.");
}

public Mono<String> retryFallback(Throwable ex) {
        if (ex instanceof TimeoutException) { // This is configured in application props of when retry should happen
            return Mono.just("⏱️ Fallback: Timeout after retries");
        } else {
            return Mono.just("❌ Fallback: " + ex.getClass().getSimpleName());
        }
    }

    public Mono<String> circuitFallback(Throwable ex) {
        return Mono.just("🛑 CircuitBreaker fallback: MS-2 unavailable");
    }
}

Consider the scenario where MS-1 calls MS-2:

* Circuit Breaker will prevent MS-1 from making repeated calls to MS-2 if it detects failures (e.g., 50% failure rate).
* If the call is not successful, Retry will attempt the request a few more times before either giving up or executing a fallback.
* If MS-2 becomes slow (e.g., response time > 2s), a TimeLimiter will trigger a timeout, and MS-1 will retry or fall back.
* In case of too many calls hitting MS-2, the RateLimiter will block some requests to avoid overloading it.
* Bulkhead limits concurrent calls to MS-2 to ensure that it doesn't get overwhelmed by too many requests at once.
* Health checks will be continuously monitored to ensure that MS-2 is healthy, and Kubernetes will route traffic only to healthy instances.

-------------------------------------------------------------------------------------------------

17. What is bulkhead pattern

The Bulkhead Pattern is one of the resilience patterns commonly used in microservice architectures to improve fault tolerance and isolation
 In a microservice system, if one service (or one part of a service) fails, it doesn't bring down the whole system.

Semaphore Bulkhead for External Service Calls
Imagine you have a Spring Boot application that calls an external API to fetch product details. You want to limit the number of concurrent requests
that can be made to the external API at any given time because the external service might get overwhelmed with too many concurrent calls.

Example code :
Step 1: Setup the Service with Semaphore Bulkhead

import io.github.resilience4j.bulkhead.annotation.Bulkhead;
import org.springframework.stereotype.Service;

@Service
public class ProductService {

    @Bulkhead(name = "productServiceBulkhead", type = Bulkhead.Type.SEMAPHORE)
    public String getProducts() {
        // Simulate calling an external API which takes time
        try {
            Thread.sleep(2000);  // Simulate API delay
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
        return "Product list fetched";
    }
}

@Bulkhead annotation is used to apply the Semaphore Bulkhead pattern to the getProducts() method.
This method simulates an external API call with a 2-second delay (Thread.sleep(2000)).

Step 2: Configuration in application.yml
In your configuration, you define the maxConcurrentCalls setting to control how many requests can run concurrently.
resilience4j:
  bulkhead:
    instances:
      productServiceBulkhead:
        maxConcurrentCalls: 3  # Limit to 3 concurrent requests

maxConcurrentCalls is set to 3, meaning no more than 3 requests to getProducts() can be in-progress simultaneously.

Step 3: How It Works (Request Flow)
Request 1: The first request to /products comes in and acquires a permit from the semaphore. Now 1 task is running.
Request 2: The second request comes in and also acquires a permit. Now there are 2 tasks running concurrently.
Request 3: The third request comes in and acquires a permit. Now there are 3 tasks running concurrently.
Request 4: The fourth request comes in, but the semaphore only allows 3 concurrent tasks. Since all the "permits" are taken, this request will either:
Wait for a permit to become available, or Be rejected depending on how you've configured it.
Request 5: The fifth request comes in and will also wait for a permit to become available.

When to Use Semaphore Bulkhead:
For limiting access to shared resources like an external service, database, or critical section in the code, without needing to manage threads directly.
When you want to control task concurrency rather than thread usage.
--------------------------------------------------------------------------------------------

18. What are the design patterns that can be implemented in Microservices?
-These patterns provide the building blocks for developing scalable, reliable, and maintainable
microservices. They address issues like service discovery, fault tolerance, data consistency, security,
and inter-service communication. The choice of patterns depends on the use case, system requirements,
and operational goals of the microservices architecture.

API Gateway Pattern* (Spring Cloud Gateway)
Service Discovery Pattern* (Netflix Eureka, Zookeeper)
Circuit Breaker Pattern* (Resilience4j,Hystrix,  Spring Cloud Circuit Breaker)
Saga Pattern* (Camunda)
Strangler Fig Pattern
Client-Side Load Balancing Pattern (Netflix Ribbon, Spring Cloud LoadBalancer)
Observer Pattern* (Kafka, RabbitMQ)
Sidecar Pattern

--------------------------------------------------------------------------------------------------
19. What is Saga pattern? How do you handle transactions across multiple microservices?

The Saga Pattern is a design pattern used to manage distributed transactions and long-running processes,
typically in microservices architectures. Unlike traditional monolithic systems where a transaction can be handled by a single service, in a distributed system, each step of a business process may be handled by a different service. This introduces the challenge of maintaining consistency and handling failures across multiple services.

The Saga Pattern solves this problem by breaking down a long-running transaction into a series of
smaller, isolated transactions (called "sagas"). Each of these transactions has a compensating action
that can be triggered in case of failure to undo the work done by previous steps

Key Concepts:
* Saga: A sequence of local transactions where each transaction is managed by a different service.
If a transaction fails, the saga ensures that compensating transactions are triggered to revert the changes made by previous steps.

* Local Transactions: Each step of the saga is a local transaction executed by a specific service. These local transactions are typically short-running and complete within the service's own boundaries.

* Compensating Transactions: If one step in the saga fails, compensating transactions are executed to reverse the work done in the previous steps. For example, if a payment service successfully processes a payment but an order service fails, a compensating transaction might cancel the payment.

* Choreography vs Orchestration:
   Choreography: Each service knows what to do next in case of a failure, and they communicate with each other in a decentralized manner. There is no central coordinator; each service acts as both the participant and the orchestrator.
   Orchestration: There is a central service (or orchestrator) that controls the flow of the saga, including deciding the next step and handling failures.

Example:
Let's consider an example of an online purchase process where a customer buys an item,
and the steps might be:

a. Reserve Item: A service reserves the item in stock.
b. Charge Payment: A service processes the payment.
c. Ship Item: A service ships the item to the customer.
d. If the payment step fails after reserving the item, a compensating transaction might be:
Cancel Reservation: The service would release the reserved item so it can be sold to someone else.

Pros of Saga Pattern:
Resilience: By breaking down a long-running transaction into smaller steps, the system can recover from partial failures more gracefully.
Scalability: Since each service only manages its own transactions, it can be scaled independently.
Decentralized: Choreography allows each service to be more autonomous.

Cons of Saga Pattern:
Complexity: Managing multiple services and ensuring consistency can be complicated.
Eventual Consistency: Unlike ACID transactions, sagas are based on eventual consistency, which means there might be a delay before the system reaches a consistent state after a failure.

public class SagaOrchestrator {

    private final OrderService orderService = new OrderService();
    private final PaymentService paymentService = new PaymentService();
    private final ShippingService shippingService = new ShippingService();

    public void executeSaga(String orderId) {
        try {
            // Step 1: Reserve item
            if (!orderService.reserveItem(orderId)) {
                throw new RuntimeException("Item reservation failed");
            }

            // Step 2: Charge payment
            if (!paymentService.charge(orderId)) {
                throw new RuntimeException("Payment failed");
            }

            // Step 3: Ship item
            if (!shippingService.ship(orderId)) {
                throw new RuntimeException("Shipping failed");
            }

            System.out.println("[Saga] Order " + orderId + " completed successfully.");

        } catch (Exception e) {
            System.out.println("[Saga] Error: " + e.getMessage());
            compensate(orderId);
        }
    }

    private void compensate(String orderId) {
        // Roll back in reverse order
        shippingService.cancelShipping(orderId);
        paymentService.refund(orderId);
        orderService.cancelReservation(orderId);
        System.out.println("[Saga] Compensation completed for order " + orderId);
    }

    // --- Services below (simplified) ---

    static class OrderService {
        boolean reserveItem(String orderId) {
            System.out.println("[OrderService] Reserved item for " + orderId);
            return true;
        }

        void cancelReservation(String orderId) {
            System.out.println("[OrderService] Canceled reservation for " + orderId);
        }
    }

    static class PaymentService {
        boolean charge(String orderId) {
            System.out.println("[PaymentService] Charged payment for " + orderId);
            return true; // Simulate success
        }

        void refund(String orderId) {
            System.out.println("[PaymentService] Refunded payment for " + orderId);
        }
    }

    static class ShippingService {
        boolean ship(String orderId) {
            System.out.println("[ShippingService] Shipped order " + orderId);
            return false; // Simulate failure
        }

        void cancelShipping(String orderId) {
            System.out.println("[ShippingService] Canceled shipping for " + orderId);
        }
    }

    // --- Main method to run the saga ---
    public static void main(String[] args) {
        SagaOrchestrator saga = new SagaOrchestrator();
        saga.executeSaga("ORDER123");
    }
}

----------------------------------------------------------------------------------------------------
20. 🌿 What is the Strangler Fig Pattern?
* The Strangler Fig Pattern is a software design approach used for gradually replacing or migrating
 a legacy system by incrementally building a new system around the edges, slowly "strangling" the old
 system until it can be fully retired.
* The name comes from the strangler fig tree, which grows around an existing tree and eventually replaces it.

 How it works:
You leave the old system running but route some functionality or traffic to a new system/module.
Over time, more and more functionality is redirected to the new system.
Eventually, the old system is completely replaced without a big-bang rewrite.

----------------------------------------------------------------------------------------------------
21. ACID properties in the context of Java, particularly when working with databases using JDBC,
JPA/Hibernate, or Spring Transaction Management.

 Technologies Involved:
Spring Framework (especially @Transactional)
Spring Data JPA
Hibernate (the default JPA provider)
Relational Database (e.g., MySQL, PostgreSQL)

| Property        | Meaning                                                       |
| --------------- | ------------------------------------------------------------- |
|     Atomicity   | All parts of a transaction succeed or none do.                |
|     Consistency | The database moves from one valid state to another.           |
|     Isolation   | Concurrent transactions do not interfere with each other.     |
|     Durability  | Once committed, changes are permanent even if a crash occurs. |

Using Spring with JPA/Hibernate
Spring provides declarative transaction management which handles ACID behind the scenes.
@Service
public class BankService {

    @Autowired
    private AccountRepository accountRepo;

    @Transactional(isolation = Isolation.READ_COMMITTED) // Default
    public void transfer(Long fromId, Long toId, double amount) {
        Account from = accountRepo.findById(fromId).orElseThrow();
        Account to = accountRepo.findById(toId).orElseThrow();

        from.setBalance(from.getBalance() - amount);
        to.setBalance(to.getBalance() + amount);

        // JPA will commit automatically or rollback if exception is thrown
    }
}

ACID Mapping in Spring + JPA :
Atomicity: Spring’s @Transactional ensures rollback on exceptions.
Consistency: JPA validates and manages entity states.
Isolation: Controlled via @Transactional(isolation = Isolation.SERIALIZABLE) etc.
Durability: Changes committed to the DB are durable.

Isolation.DEFAULT
Isolation.READ_UNCOMMITTED
Isolation.READ_COMMITTED
Isolation.REPEATABLE_READ
Isolation.SERIALIZABLE

--------------------------------------------------------------------------------------------------
22. Diff between kibana and zipkin

| Aspect                     | Kibana                                                                                      | Zipkin                                                                          |
| -------------------------- | ------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |
| **Primary Use Case**       | Visualization and analysis of **logs** and **metrics** from various sources (Elasticsearch) | Visualization and analysis of **distributed traces** (timing data for requests) |
| **Data Type**              | Logs, metrics, events                                                                       | Distributed tracing spans (trace & timing info)                                 |
| **Integration**            | Works with the **Elastic Stack** (Elasticsearch, Logstash, Beats)                           | Works with tracing instrumentation libraries (e.g., Brave, OpenTelemetry)       |
| **Focus**                  | Searching, filtering, and analyzing large volumes of log data                               | Visualizing request flows and latencies across microservices                    |
| **Output**                 | Dashboards with charts, graphs, search results                                              | Trace timelines showing calls between services and durations                    |
| **Use in Troubleshooting** | Log aggregation to find errors, exceptions, trends                                          | Pinpoint latency bottlenecks and failures in distributed transactions           |
| **Architecture**           | Part of Elastic Stack                                                                       | Standalone distributed tracing system                                           |
| **Example**                | View logs from servers, apps, network devices                                               | View how a user request passes through multiple microservices                   |

When to use which?

Use Kibana if you want to:
Search and analyze logs.
Create dashboards for metrics and logs.
Perform log aggregation and monitoring.

Use Zipkin if you want to:
Trace requests as they flow through distributed systems.
Identify where latency or failures occur across services.
Visualize service dependencies and call sequences.

| Tool   | Logs & Metrics | Distributed Tracing | Visualization of Request Flows |
| ------ | -------------- | ------------------- | ------------------------------ |
| Kibana | ✅              | ❌                   | ❌                              |
| Zipkin | ❌              | ✅                   | ✅                              |

-------------------------------------------------------------------------------------------

22. How pagination is implemented in REST API's
- You want to fetch chunks of data (pages) instead of loading everything at once
Spring Boot
Spring Data JPA
Pageable, Page<T> interfaces

Step 1 :
@Entity
public class User {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String name;
    private String email;
    // Getters and Setters
}

Step 2 :
public interface UserRepository extends JpaRepository<User, Long> {
    // No need to write any code — JpaRepository includes pagination support
}

Step 3 :
@Service
public class UserService {

    @Autowired
    private UserRepository userRepository;

    public Page<User> getAllUsers(Pageable pageable) {
        return userRepository.findAll(pageable);
    }
}

Step 4 :
@RestController
@RequestMapping("/api/users")
public class UserController {

    @Autowired
    private UserService userService;

    @GetMapping
    public ResponseEntity<Page<User>> getUsers(
            @RequestParam(defaultValue = "0") int page,
            @RequestParam(defaultValue = "10") int size,
            @RequestParam(defaultValue = "id") String sortBy
    ) {
        Pageable pageable = PageRequest.of(page, size, Sort.by(sortBy));
        Page<User> userPage = userService.getAllUsers(pageable);
        return ResponseEntity.ok(userPage);
    }
}

GET /api/users?page=1&size=5&sortBy=name  (For every new page this call will be done)
✅ Returns users 6–10, sorted by name.

--------------------------------------------------------------------------------------

23. What is idempotence in REST API's?

--------------------------------------------------------------------------------------
24. Kubernetes Load Balancing — How it Works /
How load balancing is handled in your project ?

- When you call: http://thirdpartymgmt/...
you're hitting the Kubernetes Service named thirdpartymgmt.
This service sits in front of multiple Pods (replicas of your microservice) and handles load balancing across
them automatically.

🔧 Internally:
thirdpartymgmt is a ClusterIP service (default type).
Kubernetes DNS (kube-dns or CoreDNS) resolves thirdpartymgmt to a virtual IP inside the cluster.
That virtual IP maps to a list of healthy Pods behind the service (using selectors).
The request is load balanced across the available Pods using iptables or IPVS, depending on your K8s setup.

| Mechanism             | Description                                                                          |
| --------------------- | ------------------------------------------------------------------------------------ |
| **iptables**          | Packets are NAT'd and routed round-robin to a pod behind the service.                |
| **IPVS** (if enabled) | Provides more advanced and efficient load balancing, especially for high throughput. |

http://thirdpartymgmt/thirdpartymgmt/rs/v1/thirdparty/accounts/123/placement/recall
Each request could hit a different pod based on load balancing by the service.
You can see which pod handled a request (for debugging) by logging the pod hostname or IP in your application.

| Component               | Role                                      |
| ----------------------- | ----------------------------------------- |
| `http://thirdpartymgmt` | Resolved by K8s DNS to a ClusterIP        |
| ClusterIP               | Routes traffic to one of the backing pods |
| Load Balancing          | Done automatically via iptables or IPVS   |

🔧 Key Components & Files Involved

1. Deployment — defines pods (replicas) of your microservice
📄 File: thirdpartymgmt-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thirdpartymgmt
spec:
  replicas: 3  # number of pods to load balance across
  selector:
    matchLabels:
      app: thirdpartymgmt
  template:
    metadata:
      labels:
        app: thirdpartymgmt
    spec:
      containers:
      - name: thirdpartymgmt
        image: yourregistry/thirdpartymgmt:latest
        ports:
        - containerPort: 8080

2. Service — exposes pods internally in the cluster, and load balances across them
📄 File: thirdpartymgmt-service.yaml

apiVersion: v1
kind: Service
metadata:
  name: thirdpartymgmt // this will be out service name (https://thirdpartymgmt)
spec:
  selector:
    app: thirdpartymgmt
  ports:
  - protocol: TCP
    port: 80         # Service port (targeted by clients)
    targetPort: 8080 # Container port in the pods
  type: ClusterIP    # Default type for internal-only load balancing

📌 This service allows internal access to http://thirdpartymgmt and load balances across the pods matched
by app: thirdpartymgmt.

3. DNS Resolution (automatic)
No file needed — Kubernetes automatically handles service discovery via CoreDNS.
You can resolve the service as:
http://thirdpartymgmt (from same namespace)
http://thirdpartymgmt.<namespace>.svc.cluster.local (from other namespaces)

4. (Optional) Ingress — for external traffic (not needed for internal load balancing)
If you're accessing the service from outside the cluster, you’d define an Ingress, but for internal-only load balancing,
it’s not required.

🔄 Internal Load Balancing Process
A pod (client) makes a request to http://thirdpartymgmt/...
CoreDNS resolves thirdpartymgmt to a virtual ClusterIP
The Kube proxy (using iptables or IPVS) routes the traffic to one of the pods behind the service via round-robin

Command to check on which IP our app is running : "kubectl get svc thirdpartymgmt"
System.out.println("Handling request on pod: " + System.getenv("HOSTNAME"));


---------------------------------------------------------------------------------
 25. What is Service Discovery? How it is implemented ?
 - Service Discovery is the mechanism by which one pod finds and communicates with another pod (or service) without hardcoding IP addresses.

 In Kubernetes, this is achieved through:

 DNS-based resolution
 Services (like ClusterIP) as stable endpoints in front of pods

✅ In Your Setup
You have:

A Deployment creating multiple pods (replicas) of your microservice.
A Service named thirdpartymgmt exposing those pods internally using type ClusterIP.

kind: Service
metadata:
  name: thirdpartymgmt
spec:
  selector:
    app: thirdpartymgmt
  ports:
    - port: 80
      targetPort: 8080
🧭 How Service Discovery Works Here
🔗 1. Service Name = DNS Entry
Kubernetes automatically creates a DNS name for your service:

thirdpartymgmt.<namespace>.svc.cluster.local
Or, from the same namespace, just:

http://thirdpartymgmt
So when a pod runs:

curl http://thirdpartymgmt/thirdpartymgmt/rs/v1/thirdparty/accounts/123/placement/recall
🧠 Here's what happens:
The DNS query thirdpartymgmt goes to CoreDNS (built into the cluster).
CoreDNS looks up the ClusterIP assigned to the service.
The request is routed to that virtual IP, which is managed by kube-proxy.
Kube-proxy (via iptables or IPVS) picks one of the available pods behind the service.
The request is sent to the pod on port 8080.

🔁 Visual Flow

Client Pod ──> http://thirdpartymgmt ──┬─> Pod A (8080)
                                      ├─> Pod B (8080)
                                      └─> Pod C (8080)
Each request is load balanced among the pods.

-------------------------------------------

Service discover :
+----------------+           +------------------+            +------------------+
|  Client Pod    |           |    CoreDNS       |            |  Kubernetes      |
| (calls URL)    |  DNS      | (internal DNS)   |            |  Service         |
|                | --------> | (resolves name)  | ---------> | (ClusterIP)      |
|                |           |                  |            | (virtual IP)     |
+----------------+           +------------------+            +------------------+
                                                               |           |
                                                           +---+----+  +---+----+
                                                           | Pod A  |  | Pod B  |
                                                           +--------+  +--------+
Step-by-step:
Client Pod wants to call your microservice:
It tries to call http://thirdpartymgmt.
The pod asks CoreDNS:
“Hey, what’s the IP address for thirdpartymgmt?”
CoreDNS replies with the ClusterIP:
A virtual IP that Kubernetes assigned to the service.
The pod sends the request to the ClusterIP.
Kubernetes routes the request from the ClusterIP to one of the actual pods (Pod A or Pod B).
Pod A or Pod B processes the request and sends back the response.

| Term      | Role                                          |
| --------- | --------------------------------------------- |
| DNS       | The general system that turns names → IPs     |
| CoreDNS   | The DNS server inside Kubernetes              |
| ClusterIP | Virtual stable IP that points to your pods    |
| Service   | The Kubernetes object that owns the ClusterIP |

----
Step-by-step Service Discovery in Kubernetes
1. Define and deploy your pods via a Deployment
Create multiple replicas of your microservice pods labeled (e.g., app: thirdpartymgmt).
Pods get dynamically assigned IPs inside the cluster.

2. Create a Kubernetes Service (type: ClusterIP)
The service selects pods based on labels (app: thirdpartymgmt).
Kubernetes assigns a stable ClusterIP to this service.
The service exposes port 80 and forwards traffic to pods’ container port (e.g., 8080).

3. Kubernetes DNS (CoreDNS) auto-creates DNS entries for services
Inside the cluster, thirdpartymgmt resolves to the service’s ClusterIP automatically.
From the same namespace, clients can use the short name thirdpartymgmt.
From other namespaces, full DNS name is thirdpartymgmt.<namespace>.svc.cluster.local.

4. Client pod makes a request to http://thirdpartymgmt/...
The request resolves the DNS name thirdpartymgmt to the ClusterIP by CoreDNS.

5. Kube-proxy routes traffic from ClusterIP to pod IPs
The service IP acts as a virtual IP proxy.
Using iptables or IPVS, kube-proxy load balances the request across the healthy pods behind the service.

6. One of the selected pods receives the request
Pod processes the request and returns the response.

7. Repeat for subsequent requests
Load balancing continues for every new request, distributing load among pods.


------------------------------------------------------------------------

🚪 What is Ingress in Kubernetes?
Ingress is a Kubernetes object that acts like a smart entry gate for your cluster.
It allows external HTTP/HTTPS traffic to reach your internal Services (microservices).

🧠 Think of it like this:
You have multiple microservices running inside your cluster.
You want to expose them to the outside world (e.g., from a browser or API client).
Instead of opening ports for each service, you define one common entry point — the Ingress.
Based on the URL path or hostname, Ingress routes the request to the correct service.

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-ingress
spec:
  rules:
    - host: myapp.example.com
      http:
        paths:
          - path: /payments
            pathType: Prefix
            backend:
              service:
                name: payment-service
                port:
                  number: 80
          - path: /orders
            pathType: Prefix
            backend:
              service:
                name: order-service
                port:
                  number: 80

-----------------------------------------------------------------------------
27. What is Spring Boot’s Actuator, and how is it useful in microservices?
Spring Boot Actuator provides a set of production-ready features like health checks, metrics,
application information, and more. It helps in monitoring microservices by providing endpoints such as
/actuator/health, /actuator/metrics, /actuator/info, etc. This is crucial for maintaining and monitoring
microservices in a production environment

/actuator/metrics
Exposes application metrics like memory usage, JVM stats, garbage collection counts, and more.

/actuator/health
Provides detailed health information about your application, such as database connectivity, disk space, and other critical services.

/actuator/env
Exposes information about the current environment, including system properties, environment variables, and application properties.
------------------------------------------------------------------------------
28. What is Spring Cloud Config?
 Spring Cloud Config is a centralized configuration server that stores configuration properties for
applications running in different environments. It allows microservices to fetch configuration
properties from a central repository, ensuring consistency across multiple instances of services.

-------------------------------------------------------------------------------

29. How does Spring Cloud handle service discovery?
Spring Cloud uses service discovery to allow services to find and communicate with each other dynamically.
Netflix Eureka is commonly used for service discovery. Services register themselves with Eureka, and
other services can look up these services using Eureka's API.

------------------------------------------------------------------------------

30. What is an API Gateway, and why is it used in microservices?
An API Gateway is a server that acts as an entry point for client requests to access multiple microservices.
 It handles routing, load balancing, security, and other cross-cutting concerns. Popular implementations
are Zuul and Spring Cloud Gateway.

-----------------------------------------------------------------------------
31. How do you manage inter-service communication in a microservices architecture?
Synchronous communication: Using REST (HTTP) or gRPC for real-time communication.

Asynchronous communication: Using message brokers like RabbitMQ, Kafka, or JMS for decoupled and
 reliable communication.

------------------------------------------------------------------------------

32.What are the different types of database strategies used in microservices?

Database per service: Each microservice has its own database, ensuring loose coupling.

Shared database: Multiple services share the same database, though this is not recommended due to tight coupling.

-------------------------------------------------------------------------------

33. What is the role of Docker and Kubernetes in microservices?
Docker: Docker containers are used to package microservices along with their dependencies,
ensuring they run consistently across different environments. It simplifies the deployment of microservices.

Kubernetes: Kubernetes is used for orchestrating and managing Docker containers at scale. It automates
the deployment, scaling, and management of microservices.

--------------------------------------------------------------------------------

34. How do you ensure data consistency in a microservices architecture?

Eventual Consistency: Microservices might use eventual consistency to achieve data synchronization across
services. This can be achieved through event-driven architectures, using message brokers (Kafka, RabbitMQ).

Distributed transactions: Using patterns like Saga or compensating transactions to manage consistency.

---------------------------------------------------------------------------------

